{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·∫øn chung s·ª≠ d·ª•ng xuy√™n su·ªët\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('P:/7. User/Tuong')\n",
    "from DB_ALL import SQL_NLTT_NOIBO, Database_TTD\n",
    "\n",
    "# C·∫•u h√¨nh chung\n",
    "PATH = r\"Z:\\Sky-image\\Data\"  # ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc\n",
    "OUTPUT_DIR = r\"C:\\Khue\\H9_Solar_Power_Forecasting\\data\\processed\\image\"  # Th∆∞ m·ª•c l∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω\n",
    "START_DATE = datetime.datetime(2025, 1, 1)\n",
    "END_DATE = datetime.datetime(2025, 1, 2)\n",
    "PLOT_START = datetime.datetime(2025, 3, 15)\n",
    "PLOT_END = datetime.datetime(2025, 3, 20)\n",
    "IMG_SIZE_PROCESS = (256, 256)  # K√≠ch th∆∞·ªõc ·∫£nh khi x·ª≠ l√Ω ban ƒë·∫ßu\n",
    "IMG_SIZE_MODEL = (32, 32)  # K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o m√¥ h√¨nh\n",
    "SEQ_LENGTH = 6  # ƒê·ªô d√†i chu·ªói ƒë·∫ßu v√†o\n",
    "PRED_LENGTH = 6  # ƒê·ªô d√†i d·ª± ƒëo√°n\n",
    "CHANNELS_4 = ['b07_', 'b13_', 'b08_', 'b03_']\n",
    "CHANNELS = ['b07_', 'b13_', 'b08_', 'b03_', 'arm', 'cve', 'dms', 'dnc', 'dsl', 'dst', 'irv', 'ngt', 'snd', 'tre', 'trm', 'vir']\n",
    "# CHANNELS = ['arm', 'cve', 'dms', 'dnc', 'dsl', 'dst', 'irv', 'ngt', 'snd', 'tre', 'trm', 'vir']\n",
    "NUM_CHANNELS = len(CHANNELS)\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = datetime.timedelta(minutes=10)\n",
    "UTC_OFFSET = datetime.timedelta(hours=7)\n",
    "\n",
    "# Kh·ªüi t·∫°o scaler to√†n c·ª•c\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# %% Cell 2: X·ª≠ l√Ω d·ªØ li·ªáu c√¥ng su·∫•t\n",
    "def query_power_data(start_date, end_date):\n",
    "    print(\"üîÑ ƒêang load d·ªØ li·ªáu c√¥ng su·∫•t...\")\n",
    "    db = SQL_NLTT_NOIBO()\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    df = pd.DataFrame.from_records(db.query(f\"\"\"\n",
    "    SELECT a.THOIDIEM_THUTHAP, a.CONGSUAT_KHOIPHUC as P_uoc\n",
    "    FROM DB_DGM.dbo.NLTT_UOCTINH_CONGSUAT a\n",
    "    INNER JOIN DB_DGM.dbo.NLTT_NHAMAY b ON a.ID_NM = b.ID_NM \n",
    "    WHERE a.THOIDIEM_THUTHAP >= '{start_date_str}' \n",
    "    AND a.THOIDIEM_THUTHAP < '{end_date_str}' \n",
    "    AND b.ID_LOAIHINH = 9\n",
    "    AND a.ID_NM = 353\n",
    "    ORDER BY a.THOIDIEM_THUTHAP\n",
    "    \"\"\"), columns=['NGAY', 'P'])\n",
    "\n",
    "    # Rename column for clarity and use NGAY (datetime) for resampling\n",
    "    df.rename(columns={\"P\": \"P_uoc\"}, inplace=True)\n",
    "    # Use NGAY column (which is datetime) for resampling instead of Time\n",
    "    df = df.set_index(\"NGAY\").resample('10T').mean()\n",
    "    power_df = df.reset_index()\n",
    "    # Keep the full datetime in the Time column, not just the time part\n",
    "    power_df.rename(columns={\"NGAY\": \"Time\"}, inplace=True)\n",
    "    \n",
    "    # Fit scaler v·ªõi d·ªØ li·ªáu P_uoc g·ªëc\n",
    "    scaler.fit(power_df[['P_uoc']].dropna())  # Dropna ƒë·ªÉ tr√°nh NaN g√¢y l·ªói\n",
    "    power_lookup = power_df.set_index('Time')['P_uoc'].to_dict()\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ load {len(power_df)} b·∫£n ghi\")\n",
    "    print(\"D·ªØ li·ªáu m·∫´u:\", power_df.head())\n",
    "    print(\"Lookup m·∫´u:\", {k: power_lookup[k] for k in list(power_lookup.keys())[:5]})\n",
    "    return power_df, power_lookup, scaler\n",
    "\n",
    "# Truy v·∫•n d·ªØ li·ªáu to√†n c·ª•c\n",
    "power_df, power_lookup, scaler = query_power_data(START_DATE - TIME_STEP * SEQ_LENGTH, END_DATE + TIME_STEP * PRED_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def find_file(filename):\n",
    "    \"\"\"\n",
    "    T√¨m file theo t√™n trong t·∫•t c·∫£ c√°c ·ªï ƒëƒ©a tr√™n h·ªá th·ªëng (C, D, E, ...)\n",
    "    \"\"\"\n",
    "    drives = [\n",
    "        f\"{d}:\\\\\" for d in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" if os.path.exists(f\"{d}:\\\\\")\n",
    "    ]\n",
    "\n",
    "    for drive in drives:\n",
    "        for root, _, files in os.walk(drive):\n",
    "            if filename in files:\n",
    "                return os.path.join(root, filename)\n",
    "\n",
    "    return None  # Tr·∫£ v·ªÅ None n·∫øu kh√¥ng t√¨m th·∫•y\n",
    "# %% Cell 3: Load v√† x·ª≠ l√Ω ·∫£nh\n",
    "def load_and_process_image(path, plant_name, save_path=None, default_img=None):\n",
    "    \"\"\"X·ª≠ l√Ω ·∫£nh v√† l∆∞u, tr·∫£ v·ªÅ m·∫£ng ·∫£nh. N·∫øu l·ªói, d√πng ·∫£nh m·∫∑c ƒë·ªãnh v√† v·∫´n l∆∞u.\"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            # 1. ƒê·ªçc d·ªØ li·ªáu nh√† m√°y\n",
    "            csv_filename = \"thongtintinh_farm.csv\"\n",
    "            csv_path = find_file(csv_filename)\n",
    "\n",
    "            if csv_path is None:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y file {csv_filename} trong h·ªá th·ªëng!\")\n",
    "                return None\n",
    "\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df = df.dropna(subset=[\"VIDO\", \"KINHDO\"])  # Lo·∫°i b·ªè d√≤ng kh√¥ng c√≥ lat/lon\n",
    "\n",
    "            # 2. L·ªçc d·ªØ li·ªáu theo nh√† m√°y\n",
    "            plant_data = df[df[\"TEN_NM\"] == plant_name]\n",
    "\n",
    "            if plant_data.empty:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y nh√† m√°y '{plant_name}' trong d·ªØ li·ªáu.\")\n",
    "                return None\n",
    "\n",
    "            # 3. ƒê·ªçc k√≠ch th∆∞·ªõc ·∫£nh\n",
    "            width, height = img.size\n",
    "\n",
    "            # 4. X√°c ƒë·ªãnh khung t·ªça ƒë·ªô\n",
    "            min_lon, max_lon = 80, 115\n",
    "            max_lat, min_lat = 30, 0\n",
    "\n",
    "            # H√†m chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô lat/lon sang pixel\n",
    "            def latlon_to_pixel(\n",
    "                lat,\n",
    "                lon,\n",
    "                min_lon=min_lon,\n",
    "                max_lon=max_lon,\n",
    "                min_lat=min_lat,\n",
    "                max_lat=max_lat,\n",
    "                img_width=width,\n",
    "                img_height=height,\n",
    "            ):\n",
    "                # Kinh ƒë·ªô n·ªôi suy theo chi·ªÅu ngang\n",
    "                x = (lon - min_lon) / (max_lon - min_lon) * img_width\n",
    "                # Vƒ© ƒë·ªô n·ªôi suy theo chi·ªÅu d·ªçc (l∆∞u √Ω: y tƒÉng t·ª´ tr√™n xu·ªëng)\n",
    "                y = (max_lat - lat) / (max_lat - min_lat) * img_height\n",
    "                return x, y\n",
    "\n",
    "            # H√†m t√≠nh kho·∫£ng c√°ch lat/lon t·ª´ km\n",
    "            def compute_delta_lat(km):\n",
    "                return km / 111\n",
    "\n",
    "            def compute_delta_lon(lat, km):\n",
    "                return km / (111 * math.cos(math.radians(lat)))\n",
    "\n",
    "            # 5Ô∏è‚É£ X√°c ƒë·ªãnh v√πng crop\n",
    "            half_side_km = 50  # B√°n k√≠nh 50km t·ª´ trung t√¢m\n",
    "\n",
    "            for _, row in plant_data.iterrows():\n",
    "                lat_center, lon_center = row[\"VIDO\"], row[\"KINHDO\"]\n",
    "                x_center, y_center = latlon_to_pixel(lat_center, lon_center)\n",
    "\n",
    "                d_lat = compute_delta_lat(half_side_km)\n",
    "                d_lon = compute_delta_lon(lat_center, half_side_km)\n",
    "\n",
    "                lat_north, lat_south = lat_center + d_lat, lat_center - d_lat\n",
    "                lon_west, lon_east = lon_center - d_lon, lon_center + d_lon\n",
    "\n",
    "                x_nw, y_nw = latlon_to_pixel(lat_north, lon_west)\n",
    "                x_ne, y_ne = latlon_to_pixel(lat_north, lon_east)\n",
    "                x_sw, y_sw = latlon_to_pixel(lat_south, lon_west)\n",
    "                x_se, y_se = latlon_to_pixel(lat_south, lon_east)\n",
    "\n",
    "                x_min = min(x_nw, x_ne, x_sw, x_se)\n",
    "                y_min = min(y_nw, y_ne, y_sw, y_se)\n",
    "                x_max = max(x_nw, x_ne, x_sw, x_se)\n",
    "                y_max = max(y_nw, y_ne, y_sw, y_se)\n",
    "\n",
    "            # 6Ô∏è‚É£ H√†m crop ·∫£nh\n",
    "            def crop_square(img, x_min, y_min, x_max, y_max):\n",
    "                W, H = img.size\n",
    "                bbox_w = x_max - x_min\n",
    "                bbox_h = y_max - y_min\n",
    "\n",
    "                side = max(bbox_w, bbox_h)  # c·∫°nh h√¨nh vu√¥ng\n",
    "                cx = (x_min + x_max) / 2\n",
    "                cy = (y_min + y_max) / 2\n",
    "\n",
    "                side = int(math.ceil(side))  # l√†m tr√≤n l√™n ƒë·ªÉ ch·∫Øc ch·∫Øn kh√¥ng c·∫Øt m·∫•t\n",
    "                if side > W or side > H:\n",
    "                    print(\"V√πng crop y√™u c·∫ßu l·ªõn h∆°n k√≠ch th∆∞·ªõc ·∫£nh! Gi·ªØ nguy√™n ·∫£nh.\")\n",
    "                    return img\n",
    "\n",
    "                # T√≠nh to·∫° ƒë·ªô ban ƒë·∫ßu\n",
    "                crop_xmin = int(cx - side / 2)\n",
    "                crop_ymin = int(cy - side / 2)\n",
    "                crop_xmax = crop_xmin + side\n",
    "                crop_ymax = crop_ymin + side\n",
    "\n",
    "                # D·ªùi n·∫øu tr√†n\n",
    "                if crop_xmin < 0:\n",
    "                    shift = -crop_xmin\n",
    "                    crop_xmin = 0\n",
    "                    crop_xmax += shift\n",
    "                if crop_xmax > W:\n",
    "                    shift = crop_xmax - W\n",
    "                    crop_xmax = W\n",
    "                    crop_xmin -= shift\n",
    "                if crop_ymin < 0:\n",
    "                    shift = -crop_ymin\n",
    "                    crop_ymin = 0\n",
    "                    crop_ymax += shift\n",
    "                if crop_ymax > H:\n",
    "                    shift = crop_ymax - H\n",
    "                    crop_ymax = H\n",
    "                    crop_ymin -= shift\n",
    "\n",
    "                # ƒê·∫£m b·∫£o v·∫´n vu√¥ng (n·∫øu c√≥ l·ªách 1 pixel do l√†m tr√≤n, ta ƒëi·ªÅu ch·ªânh)\n",
    "                final_w = crop_xmax - crop_xmin\n",
    "                final_h = crop_ymax - crop_ymin\n",
    "                if final_w != final_h:\n",
    "                    side2 = min(final_w, final_h)\n",
    "                    crop_xmax = crop_xmin + side2\n",
    "                    crop_ymax = crop_ymin + side2\n",
    "\n",
    "                return img.crop((crop_xmin, crop_ymin, crop_xmax, crop_ymax))\n",
    "\n",
    "            # 7Ô∏è‚É£ C·∫Øt ·∫£nh & ph√≥ng to\n",
    "            cropped_img = crop_square(img, x_min, y_min, x_max, y_max)\n",
    "            resized_img = cropped_img.resize(IMG_SIZE_PROCESS, Image.LANCZOS).convert('L')\n",
    "            \n",
    "            # Chuy·ªÉn ƒë·ªïi v√† chu·∫©n h√≥a ·∫£nh\n",
    "            img_array = np.array(resized_img, dtype=np.float32)\n",
    "            img_array = (img_array / 127.5) - 1.0\n",
    "                \n",
    "            if save_path:\n",
    "                resized_img.save(save_path)\n",
    "            return img_array\n",
    "    except (FileNotFoundError, IOError, SyntaxError) as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "        if save_path and default_img is not None:\n",
    "            Image.fromarray(((default_img + 1.0) * 127.5).astype(np.uint8)).save(save_path)\n",
    "        return default_img if default_img is not None else np.zeros(IMG_SIZE_PROCESS, dtype=np.float32)\n",
    "\n",
    "def process_and_save_images(output_folder, start_date, end_date, channels=CHANNELS_4, time_step=TIME_STEP):\n",
    "    print(f\"\\nüîÑ ƒêang load v√† x·ª≠ l√Ω ·∫£nh t·ª´ {PATH} ƒë·ªÉ l∆∞u v√†o {output_folder}...\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # T·∫°o chu·ªói th·ªùi gian li√™n ti·∫øp v·ªõi b∆∞·ªõc 10 ph√∫t\n",
    "    time_series = pd.date_range(start=start_date, end=end_date, freq='10min')\n",
    "    date_dirs = sorted(set([d.strftime(\"%Y%m%d\") for d in time_series]))\n",
    "    \n",
    "    # Kh·ªüi t·∫°o dictionary ƒë·ªÉ l∆∞u ·∫£nh g·∫ßn nh·∫•t h·ª£p l·ªá c·ªßa t·ª´ng k√™nh\n",
    "    last_images = {ch: np.zeros(IMG_SIZE_PROCESS, dtype=np.float32) for ch in channels}  # M·∫∑c ƒë·ªãnh l√† zeros\n",
    "    processed_count = 0  # ƒê·∫øm ·∫£nh x·ª≠ l√Ω t·ª´ file g·ªëc\n",
    "    saved_count = 0      # ƒê·∫øm t·ªïng s·ªë ·∫£nh l∆∞u\n",
    "    \n",
    "    # Duy·ªát qua t·ª´ng folder\n",
    "    for date_dir in date_dirs:\n",
    "        print(f\"üìÇ ƒêang x·ª≠ l√Ω folder: {date_dir}\")\n",
    "        date_path = os.path.join(PATH, date_dir)\n",
    "        \n",
    "        # L·∫•y c√°c th·ªùi ƒëi·ªÉm trong ng√†y n√†y\n",
    "        day_times = [t for t in time_series if t.strftime(\"%Y%m%d\") == date_dir]\n",
    "        \n",
    "        if os.path.exists(date_path):\n",
    "            # T·∫°o dictionary ch·ª©a ·∫£nh g·ªëc t·∫°i c√°c th·ªùi ƒëi·ªÉm trong folder\n",
    "            available_images = {}\n",
    "            for time_dir in os.listdir(date_path):\n",
    "                time_path = os.path.join(date_path, time_dir)\n",
    "                if os.path.isdir(time_path):\n",
    "                    try:\n",
    "                        dt = datetime.datetime.strptime(f\"{date_dir}T{time_dir}\", \"%Y%m%dT%H%M\")\n",
    "                        if dt in day_times:\n",
    "                            available_images[dt] = {}\n",
    "                            for file in os.listdir(time_path):\n",
    "                                for ch in channels:\n",
    "                                    if file.lower().startswith(ch) and file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                                        available_images[dt][ch] = os.path.join(time_path, file)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        # L∆∞u ·∫£nh cho t·ª´ng th·ªùi ƒëi·ªÉm trong ng√†y\n",
    "        for dt in day_times:\n",
    "            for ch in channels:\n",
    "                output_filename = f\"{ch}{dt.strftime('%Y%m%d_%H%M')}.jpg\"\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "                \n",
    "                if os.path.exists(date_path) and dt in available_images and ch in available_images[dt]:\n",
    "                    # C√≥ ·∫£nh g·ªëc, x·ª≠ l√Ω v√† l∆∞u\n",
    "                    img_path = available_images[dt][ch]\n",
    "                    img_array = load_and_process_image(img_path, plant_name='MT Solarpark 1', save_path=output_path, default_img=last_images[ch])\n",
    "                    if not np.array_equal(img_array, last_images[ch]):  # Ch·ªâ tƒÉng processed_count n·∫øu ·∫£nh m·ªõi\n",
    "                        processed_count += 1\n",
    "                    last_images[ch] = img_array  # C·∫≠p nh·∫≠t ·∫£nh g·∫ßn nh·∫•t\n",
    "                else:\n",
    "                    # Thi·∫øu ·∫£nh ho·∫∑c folder kh√¥ng t·ªìn t·∫°i, d√πng ·∫£nh g·∫ßn nh·∫•t v√† l∆∞u\n",
    "                    print(f\"‚ö†Ô∏è Thi·∫øu ho·∫∑c l·ªói ·∫£nh cho k√™nh {ch} t·∫°i {dt.strftime('%Y-%m-%d %H:%M')}, d√πng ·∫£nh g·∫ßn nh·∫•t.\")\n",
    "                    Image.fromarray(((last_images[ch] + 1.0) * 127.5).astype(np.uint8)).save(output_path)\n",
    "                \n",
    "                saved_count += 1\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω {processed_count} ·∫£nh t·ª´ file g·ªëc v√† l∆∞u t·ªïng c·ªông {saved_count} ·∫£nh v√†o {output_folder}\")\n",
    "\n",
    "# Ch·∫°y x·ª≠ l√Ω ·∫£nh\n",
    "process_and_save_images(OUTPUT_DIR, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# %% Cell 4: Load ·∫£nh t·ª´ output_folder v√† t·∫°o chu·ªói\n",
    "def load_processed_image(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img = img.resize(IMG_SIZE_MODEL)\n",
    "            img_array = np.array(img, dtype=np.float32)\n",
    "            img_array = (img_array / 127.5) - 1.0\n",
    "            return img_array\n",
    "    except (FileNotFoundError, IOError, SyntaxError) as e:\n",
    "        print(f\"Error loading {path}: {e}\")\n",
    "        return np.zeros(IMG_SIZE_MODEL, dtype=np.float32)\n",
    "\n",
    "def preprocess_images_from_folder(output_folder, start_date, end_date, channels=CHANNELS_4):\n",
    "    print(f\"\\nüîÑ ƒêang load ·∫£nh t·ª´ {output_folder} v√† t·∫°o chu·ªói d·ªØ li·ªáu...\")\n",
    "    image_records = {ch: {} for ch in channels}\n",
    "    \n",
    "    for file in os.listdir(output_folder):\n",
    "        for ch in channels:\n",
    "            if file.lower().startswith(ch) and file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                try:\n",
    "                    time_str = file[len(ch):-4]\n",
    "                    dt = datetime.datetime.strptime(time_str, '%Y%m%d_%H%M')\n",
    "                    if start_date <= dt <= end_date:\n",
    "                        image_records[ch][dt] = os.path.join(output_folder, file)\n",
    "                except ValueError as e:\n",
    "                    print(f\"‚ö†Ô∏è File {file} kh√¥ng kh·ªõp ƒë·ªãnh d·∫°ng th·ªùi gian ({e}), b·ªè qua.\")\n",
    "\n",
    "    all_times = sorted(set.union(*(set(rec.keys()) for rec in image_records.values())))\n",
    "    print(f\"üìä T√¨m th·∫•y {len(all_times)} th·ªùi ƒëi·ªÉm t·ª´ {start_date.strftime('%Y-%m-%d')} ƒë·∫øn {end_date.strftime('%Y-%m-%d')}\")\n",
    "    if all_times:\n",
    "        print(f\"Th·ªùi gian ƒë·∫ßu: {all_times[0].strftime('%Y-%m-%d %H:%M')}\")\n",
    "        print(f\"Th·ªùi gian cu·ªëi: {all_times[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
    "\n",
    "    if len(all_times) < SEQ_LENGTH:\n",
    "        print(f\"‚ö†Ô∏è S·ªë th·ªùi ƒëi·ªÉm ({len(all_times)}) √≠t h∆°n SEQ_LENGTH ({SEQ_LENGTH}), kh√¥ng th·ªÉ t·∫°o chu·ªói!\")\n",
    "        return np.array([]), []\n",
    "\n",
    "    sequences_images = []\n",
    "    sequences_times = []\n",
    "    last_images = {ch: np.zeros(IMG_SIZE_MODEL, dtype=np.float32) for ch in channels}\n",
    "\n",
    "    for i in range(len(all_times) - SEQ_LENGTH + 1):\n",
    "        time_window = all_times[i:i + SEQ_LENGTH]\n",
    "        channel_seq = []\n",
    "        for ch in channels:\n",
    "            seq_per_channel = []\n",
    "            for t in time_window:\n",
    "                if t in image_records[ch]:\n",
    "                    img = load_processed_image(image_records[ch][t])\n",
    "                    last_images[ch] = img\n",
    "                else:\n",
    "                    img = last_images[ch]\n",
    "                seq_per_channel.append(img)\n",
    "            channel_seq.append(seq_per_channel)\n",
    "        stacked_seq = np.array(channel_seq, dtype=np.float32).transpose(1, 2, 3, 0)\n",
    "        sequences_images.append(stacked_seq)\n",
    "        sequences_times.append(time_window[-1])\n",
    "\n",
    "    sequences_images = np.array(sequences_images, dtype=np.float32)\n",
    "    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω {len(sequences_images)} chu·ªói ·∫£nh\")\n",
    "    print(\"Shape c·ªßa sequences_images:\", sequences_images.shape)\n",
    "    np.save(os.path.join(OUTPUT_DIR, 'sequences_images_processed.npy'), sequences_images)\n",
    "    with open(os.path.join(OUTPUT_DIR, 'sequences_times.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(t.strftime('%Y-%m-%d %H:%M') for t in sequences_times))\n",
    "    return sequences_images, sequences_times\n",
    "\n",
    "sequences_images, sequences_times = preprocess_images_from_folder(OUTPUT_DIR, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# %% Cell 5: Gh√©p d·ªØ li·ªáu ·∫£nh v·ªõi P_uoc v√† t·∫°o dataset\n",
    "def prepare_dataset(sequences_images, sequences_times, power_lookup, scaler):\n",
    "    print(\"\\nüîÑ ƒêang gh√©p d·ªØ li·ªáu ·∫£nh v·ªõi P_uoc...\")\n",
    "    sequences_p_uoc = []\n",
    "    targets = []\n",
    "    valid_sequences_images = []\n",
    "    valid_sequences_times = []\n",
    "    \n",
    "    for i, (img_seq, seq_time_utc) in enumerate(zip(sequences_images, sequences_times)):\n",
    "        seq_time_vn = seq_time_utc + UTC_OFFSET\n",
    "        start_times_vn = [seq_time_vn - TIME_STEP * (SEQ_LENGTH - 1 - j) for j in range(SEQ_LENGTH)]\n",
    "        p_uoc_seq = [power_lookup.get(t, 0.0) for t in start_times_vn]\n",
    "        \n",
    "        target_dts_vn = [seq_time_vn + TIME_STEP * (j + 1) for j in range(PRED_LENGTH)]\n",
    "        target_powers = [power_lookup.get(dt, 0.0) for dt in target_dts_vn]\n",
    "        \n",
    "        p_uoc_array = np.array(p_uoc_seq, dtype=np.float32)\n",
    "        target_array = np.array(target_powers, dtype=np.float32)\n",
    "        \n",
    "        p_uoc_normalized = scaler.transform(p_uoc_array.reshape(-1, 1)).flatten()\n",
    "        target_normalized = scaler.transform(target_array.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        if np.any(np.isnan(p_uoc_normalized)) or np.any(np.isnan(target_normalized)):\n",
    "            continue\n",
    "        \n",
    "        valid_sequences_images.append(img_seq)\n",
    "        sequences_p_uoc.append(p_uoc_normalized)\n",
    "        targets.append(target_normalized)\n",
    "        valid_sequences_times.append(seq_time_vn)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: (((img, p), t) for img, p, t in zip(valid_sequences_images, sequences_p_uoc, targets)),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH,), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(PRED_LENGTH,), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(BATCH_SIZE)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset ƒë√£ s·∫µn s√†ng v·ªõi kho·∫£ng {len(valid_sequences_times)} m·∫´u\")\n",
    "    print(\"Shape m·∫´u ƒë·∫ßu v√†o (images):\", (BATCH_SIZE, SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS))\n",
    "    return dataset, valid_sequences_times, targets\n",
    "\n",
    "dataset, valid_sequences_times, targets = prepare_dataset(sequences_images, sequences_times, power_lookup, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# %% Cell 6: T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a m√¥ h√¨nh m·ªõi (3D CNN + GRU)\n",
    "def build_model():\n",
    "    # ƒê·∫ßu v√†o ·∫£nh: (SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS)\n",
    "    image_input = layers.Input(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS_4))\n",
    "    \n",
    "    # S·ª≠ d·ª•ng 3D CNN ƒë·ªÉ x·ª≠ l√Ω kh√¥ng gian-th·ªùi gian\n",
    "    x = layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(image_input)\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)  # Gi·∫£m k√≠ch th∆∞·ªõc kh√¥ng gian\n",
    "    x = layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    \n",
    "    # Reshape ƒë·ªÉ ƒë∆∞a v√†o GRU\n",
    "    x = layers.Reshape((-1, x.shape[2] * x.shape[3] * x.shape[4]))(x)  # (batch, SEQ_LENGTH, features)\n",
    "    \n",
    "    # S·ª≠ d·ª•ng GRU ƒë·ªÉ h·ªçc c√°c m·∫´u th·ªùi gian\n",
    "    x = layers.GRU(128, return_sequences=False)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # ƒê·∫ßu v√†o c√¥ng su·∫•t: (SEQ_LENGTH,)\n",
    "    power_input = layers.Input(shape=(SEQ_LENGTH,))\n",
    "    p = layers.Dense(64, activation='relu')(power_input)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "    \n",
    "    # K·∫øt h·ª£p hai nh√°nh\n",
    "    combined = layers.Concatenate()([x, p])\n",
    "    output = layers.Dense(PRED_LENGTH, activation='linear')(combined)\n",
    "    \n",
    "    # T·∫°o v√† bi√™n d·ªãch m√¥ h√¨nh\n",
    "    model = models.Model(inputs=[image_input, power_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae')\n",
    "    return model\n",
    "\n",
    "# Callback ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã realtime\n",
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        # Ensure matplotlib backend can work in notebook\n",
    "        plt.ioff()  # Turn off interactive mode at start\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.ax.set_title('Training and Validation Loss')\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss (MAE)')\n",
    "        self.ax.grid(True)\n",
    "        self.line1, = self.ax.plot([], [], 'b-', label='Training Loss')\n",
    "        self.line2, = self.ax.plot([], [], 'r-', label='Validation Loss')\n",
    "        self.ax.legend()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        # Update plot data\n",
    "        x = list(range(1, len(self.losses) + 1))\n",
    "        self.line1.set_data(x, self.losses)\n",
    "        self.line2.set_data(x, self.val_losses)\n",
    "        \n",
    "        # Adjust plot limits\n",
    "        self.ax.set_xlim(0, len(self.losses) + 1)\n",
    "        self.ax.set_ylim(0, max(max(self.losses), max(self.val_losses)) * 1.1)\n",
    "        \n",
    "        # Display and update\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "        \n",
    "        # Force display update using display.clear_output\n",
    "        from IPython import display\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(self.fig)\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        # Final plot showing complete training history\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.losses, label='Training Loss', color='blue')\n",
    "        plt.plot(self.val_losses, label='Validation Loss', color='red')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (MAE)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# T·∫°o m√¥ h√¨nh\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Chia dataset th√†nh train v√† validation\n",
    "def split_dataset(dataset, valid_sequences_times, split_ratio=0.8):\n",
    "    print(\"\\nüîÑ ƒêang chia dataset th√†nh train v√† validation...\")\n",
    "    dataset_size = len(valid_sequences_times)\n",
    "    train_size = int(dataset_size * split_ratio)\n",
    "    \n",
    "    dataset_list = list(dataset.unbatch())\n",
    "    train_data = dataset_list[:train_size]\n",
    "    val_data = dataset_list[train_size:]\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: (((img, p), t) for (img, p), t in train_data),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS_CHANNELS_4), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH,), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(PRED_LENGTH,), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(BATCH_SIZE)\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: (((img, p), t) for (img, p), t in val_data),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS_4), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH,), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(PRED_LENGTH,), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(BATCH_SIZE)\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ chia dataset: {len(train_data)} m·∫´u train, {len(val_data)} m·∫´u validation\")\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Gi·∫£ ƒë·ªãnh dataset v√† valid_sequences_times ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª´ Cell 5\n",
    "train_dataset, val_dataset = split_dataset(dataset, valid_sequences_times, split_ratio=0.8)\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi callback\n",
    "plot_losses = PlotLosses()\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,  # Gi·∫£m s·ªë epoch ƒë·ªÉ tƒÉng t·ªëc\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[plot_losses],\n",
    "    verbose=1\n",
    ")  # Gi·∫£m s·ªë epoch ƒë·ªÉ tƒÉng t·ªëc[plot_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# %% Cell 6: T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "def build_model():\n",
    "    image_input = layers.Input(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS))\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))(image_input)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "    \n",
    "    power_input = layers.Input(shape=(SEQ_LENGTH,))\n",
    "    p = layers.RepeatVector(SEQ_LENGTH)(power_input)\n",
    "    p = layers.LSTM(64)(p)\n",
    "    \n",
    "    combined = layers.Concatenate()([x, p])\n",
    "    output = layers.Dense(PRED_LENGTH)(combined)\n",
    "    \n",
    "    model = models.Model(inputs=[image_input, power_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# T·∫°o m√¥ h√¨nh\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Chia dataset th√†nh train v√† validation\n",
    "def split_dataset(dataset, valid_sequences_times, split_ratio=0.8):\n",
    "    print(\"\\nüîÑ ƒêang chia dataset th√†nh train v√† validation...\")\n",
    "    dataset_size = len(valid_sequences_times)\n",
    "    train_size = int(dataset_size * split_ratio)\n",
    "    \n",
    "    # Chuy·ªÉn dataset th√†nh list ƒë·ªÉ chia\n",
    "    dataset_list = list(dataset.unbatch())\n",
    "    train_data = dataset_list[:train_size]\n",
    "    val_data = dataset_list[train_size:]\n",
    "    \n",
    "    # T·∫°o l·∫°i dataset t·ª´ list\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: (((img, p), t) for (img, p), t in train_data),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH,), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(PRED_LENGTH,), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(BATCH_SIZE)\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: (((img, p), t) for (img, p), t in val_data),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH, IMG_SIZE_MODEL[0], IMG_SIZE_MODEL[1], NUM_CHANNELS), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(SEQ_LENGTH,), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(PRED_LENGTH,), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(BATCH_SIZE)\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ chia dataset: {len(train_data)} m·∫´u train, {len(val_data)} m·∫´u validation\")\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Gi·∫£ ƒë·ªãnh dataset v√† valid_sequences_times ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª´ Cell 5\n",
    "train_dataset, val_dataset = split_dataset(dataset, valid_sequences_times, split_ratio=0.8)\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi validation\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=val_dataset,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Cell 7: D·ª± ƒëo√°n v√† v·∫Ω d·ªØ li·ªáu\n",
    "def plot_predictions(model, scaler, start_date, end_date, channels=CHANNELS):\n",
    "    power_df_plot, power_lookup_plot, scaler = query_power_data(start_date - TIME_STEP * SEQ_LENGTH, end_date + TIME_STEP * PRED_LENGTH)\n",
    "    sequences_images_plot, sequences_times_plot = preprocess_images_from_folder(OUTPUT_DIR, start_date, end_date, channels)\n",
    "    if sequences_images_plot.size == 0:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ·∫£nh ƒë·ªÉ v·∫Ω!\")\n",
    "        return\n",
    "    \n",
    "    dataset_plot, valid_sequences_times_plot, targets_normalized = prepare_dataset(sequences_images_plot, sequences_times_plot, power_lookup_plot, scaler)\n",
    "    if not valid_sequences_times_plot:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ v·∫Ω!\")\n",
    "        return\n",
    "    \n",
    "    predictions_normalized = model.predict(dataset_plot)\n",
    "    predictions = scaler.inverse_transform(predictions_normalized)\n",
    "    true_values = scaler.inverse_transform(np.array(targets_normalized))\n",
    "    \n",
    "    full_times = [start_date + UTC_OFFSET + i * TIME_STEP for i in range(int((end_date - start_date).total_seconds() / 600) + PRED_LENGTH + 1)]\n",
    "    \n",
    "    full_true_step1 = np.full(len(full_times), np.nan)\n",
    "    full_pred_step1 = np.full(len(full_times), np.nan)\n",
    "    full_true_step6 = np.full(len(full_times), np.nan)\n",
    "    full_pred_step6 = np.full(len(full_times), np.nan)\n",
    "    full_true_step24 = np.full(len(full_times), np.nan)\n",
    "    full_pred_step24 = np.full(len(full_times), np.nan)\n",
    "    \n",
    "    for i, t in enumerate(valid_sequences_times_plot):\n",
    "        base_idx = int((t - (start_date + UTC_OFFSET)) / TIME_STEP)\n",
    "        for j in range(PRED_LENGTH):\n",
    "            idx = base_idx + j + 1\n",
    "            if 0 <= idx < len(full_times):\n",
    "                if j == 0:\n",
    "                    full_true_step1[idx] = true_values[i, j]\n",
    "                    full_pred_step1[idx] = predictions[i, j]\n",
    "                elif j == 5:\n",
    "                    full_true_step6[idx] = true_values[i, j]\n",
    "                    full_pred_step6[idx] = predictions[i, j]\n",
    "                elif j == 23:\n",
    "                    full_true_step24[idx] = true_values[i, j]\n",
    "                    full_pred_step24[idx] = predictions[i, j]\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(full_times, full_true_step1, label='Th·ª±c t·∫ø (B∆∞·ªõc 1)', color='blue')\n",
    "    plt.plot(full_times, full_pred_step1, label='D·ª± ƒëo√°n (B∆∞·ªõc 1)', color='blue', linestyle='--')\n",
    "    plt.plot(full_times, full_true_step6, label='Th·ª±c t·∫ø (B∆∞·ªõc 6)', color='red')\n",
    "    plt.plot(full_times, full_pred_step6, label='D·ª± ƒëo√°n (B∆∞·ªõc 6)', color='red', linestyle='--')\n",
    "    plt.plot(full_times, full_true_step24, label='Th·ª±c t·∫ø (B∆∞·ªõc 24)', color='green')\n",
    "    plt.plot(full_times, full_pred_step24, label='D·ª± ƒëo√°n (B∆∞·ªõc 24)', color='green', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Th·ªùi gian')\n",
    "    plt.ylabel('C√¥ng su·∫•t (kW)')\n",
    "    plt.title(f'So s√°nh th·ª±c t·∫ø v√† d·ª± ƒëo√°n t·ª´ {start_date.strftime(\"%d/%m/%Y\")} ƒë·∫øn {end_date.strftime(\"%d/%m/%Y\")}')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlim(start_date + UTC_OFFSET, end_date + UTC_OFFSET + TIME_STEP * PRED_LENGTH)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return predictions, power_df_plot, full_times\n",
    "predictions, power_df_plot, full_times = plot_predictions(model, scaler, PLOT_START, PLOT_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V·∫Ω power_df_plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(power_df_plot['Time'], power_df_plot['P_uoc'], label='Th·ª±c t·∫ø', color='blue')\n",
    "# plt.plot(full_times, predictions.flatten(), label='D·ª± ƒëo√°n', color='red', linestyle='--')\n",
    "plt.xlabel('Th·ªùi gian')\n",
    "# plt.ylabel('C√¥ng su·∫•t (kW)')\n",
    "plt.title(f'So s√°nh th·ª±c t·∫ø v√† d·ª± ƒëo√°n t·ª´ {PLOT_START.strftime(\"%d/%m/%Y\")} ƒë·∫øn {PLOT_END.strftime(\"%d/%m/%Y\")}')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(predictions, columns=[f\"Step_{i+1}\" for i in range(PRED_LENGTH)])\n",
    "# V·∫Ω df_pred c·ªôt step 1 v√† step 24\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(df_pred[\"Step_1\"], label='D·ª± ƒëo√°n (B∆∞·ªõc 1)', color='blue')\n",
    "# plt.plot(df_pred[\"Step_24\"], label='D·ª± ƒëo√°n (B∆∞·ªõc 24)', color='green')\n",
    "plt.xlabel('Th·ªùi gian')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(df_pred[\"Step_24\"], label='D·ª± ƒëo√°n (B∆∞·ªõc 24)', color='green')\n",
    "plt.xlabel('Th·ªùi gian')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
