{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Đang xử lý ảnh thành chuỗi dữ liệu multi-channel...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m image_records_dict:\n\u001b[0;32m    110\u001b[0m     image_records_dict[prefix]\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 112\u001b[0m sequences_images_processed, sequences_times \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_records_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_dataset_with_processed_images\u001b[39m(sequences_images_processed, sequences_times):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ghép dữ liệu ảnh với chuỗi GHI_CS đã chuẩn hóa và tạo tf.data.Dataset.\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m, in \u001b[0;36mpreprocess_images\u001b[1;34m(image_records_dict)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m time_window:\n\u001b[0;32m     77\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((p \u001b[38;5;28;01mfor\u001b[39;00m p, dt \u001b[38;5;129;01min\u001b[39;00m image_records_dict[prefix] \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m==\u001b[39m t), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 78\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(IMG_SIZE \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     79\u001b[0m     channel_seq\u001b[38;5;241m.\u001b[39mappend(img\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     80\u001b[0m multi_channel_seq\u001b[38;5;241m.\u001b[39mappend(channel_seq)\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36mload_and_process_image\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load image from disk, resize và normalize về khoảng [-1,1].\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Sử dụng tf.image.decode_image có thể tự động xử lý định dạng\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(img, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, expand_animations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:133\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_file\u001b[39m(filename, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:611\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m    614\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:634\u001b[0m, in \u001b[0;36mread_file_eager_fallback\u001b[1;34m(filename, name, ctx)\u001b[0m\n\u001b[0;32m    632\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [filename]\n\u001b[0;32m    633\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m    637\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m    638\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pvlib\n",
    "from pvlib import location\n",
    "\n",
    "# ---------- PHẦN 1: TÍNH TOÁN DỮ LIỆU CLEAR SKY ----------\n",
    "# Define date range for GMT+7 (Asia/Saigon)\n",
    "start_date = pd.Timestamp('2025-01-01 00:00:00', tz='Asia/Saigon')\n",
    "end_date = pd.Timestamp('2025-03-14 23:59:59', tz='Asia/Saigon')\n",
    "\n",
    "lat, lon = 10.76477848, 106.3148294\n",
    "site = location.Location(lat, lon, tz='Asia/Saigon')\n",
    "\n",
    "times = pd.date_range(start=start_date, end=end_date, freq='10min', tz='Asia/Saigon')\n",
    "clearsky_data = site.get_clearsky(times).reset_index().rename(columns={'index': 'Time'})\n",
    "clearsky_data.Time = pd.to_datetime(clearsky_data.Time).dt.tz_localize(None)\n",
    "clearsky_data.set_index('Time', inplace=True)\n",
    "clearsky_data = clearsky_data[['ghi']].rename(columns={'ghi': 'GHI_CS'})\n",
    "\n",
    "# ---------- PHẦN 2: XỬ LÝ DỮ LIỆU GHI_CS ----------\n",
    "power_df = clearsky_data.copy().reset_index()\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "scaler = MinMaxScaler()\n",
    "power_df['GHI_CS_normalized'] = scaler.fit_transform(power_df[['GHI_CS']])\n",
    "power_lookup = power_df.set_index('Time')['GHI_CS_normalized'].to_dict()\n",
    "\n",
    "# ---------- PHẦN 3: XỬ LÝ ẢNH VÀ TẠO PIPELINE ----------\n",
    "SEQ_LENGTH = 24\n",
    "PRED_LENGTH = 24\n",
    "IMG_SIZE = (32, 32)\n",
    "NUM_CHANNELS = 4\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "START_DATE = datetime.datetime(2025, 1, 1)\n",
    "END_DATE = datetime.datetime(2025, 1, 14)\n",
    "PATH = r\"Z:\\Sky-image\\namnvn\\Data_process\\MT Solarpark 1\"\n",
    "\n",
    "def load_and_process_image(path):\n",
    "    \"\"\"Load image from disk, resize và normalize về khoảng [-1,1].\"\"\"\n",
    "    try:\n",
    "        img = tf.io.read_file(path)\n",
    "        # Sử dụng tf.image.decode_image có thể tự động xử lý định dạng\n",
    "        img = tf.image.decode_image(img, channels=1, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = (img / 127.5) - 1.0\n",
    "        return img.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi load ảnh {path}: {e}\")\n",
    "        return np.zeros(IMG_SIZE + (1,), dtype=np.float32)\n",
    "\n",
    "def preprocess_images(image_records_dict):\n",
    "    \"\"\"Ghép các kênh ảnh thành một chuỗi dữ liệu multi-channel.\"\"\"\n",
    "    print(\"\\n🔄 Đang xử lý ảnh thành chuỗi dữ liệu multi-channel...\")\n",
    "    prefixes = ['b03_', 'b07_', 'b08_', 'b13_']\n",
    "    sequences_images = []\n",
    "    sequences_times = []\n",
    "    \n",
    "    # Tìm thời gian chung cho tất cả các kênh\n",
    "    times = set.intersection(*(set(dt for _, dt in image_records_dict[prefix]) for prefix in prefixes))\n",
    "    times = sorted(times)\n",
    "    min_length = len(times) - SEQ_LENGTH - PRED_LENGTH + 1\n",
    "    \n",
    "    for i in range(max(0, min_length)):\n",
    "        time_window = times[i:i+SEQ_LENGTH]\n",
    "        if len(time_window) != SEQ_LENGTH:\n",
    "            continue\n",
    "        multi_channel_seq = []\n",
    "        for prefix in prefixes:\n",
    "            channel_seq = []\n",
    "            for t in time_window:\n",
    "                path = next((p for p, dt in image_records_dict[prefix] if dt == t), None)\n",
    "                img = load_and_process_image(path) if path else np.zeros(IMG_SIZE + (1,), dtype=np.float32)\n",
    "                channel_seq.append(img.squeeze())\n",
    "            multi_channel_seq.append(channel_seq)\n",
    "        # Stack thành (SEQ_LENGTH, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS)\n",
    "        stacked_seq = np.stack(multi_channel_seq, axis=-1)\n",
    "        sequences_images.append(stacked_seq)\n",
    "        sequences_times.append(time_window[-1])\n",
    "    \n",
    "    sequences_images = np.array(sequences_images)\n",
    "    print(f\"✅ Đã xử lý {len(sequences_images)} chuỗi ảnh, shape: {sequences_images.shape}\")\n",
    "    return sequences_images, sequences_times\n",
    "\n",
    "# Tạo image_records_dict sử dụng cấu trúc thư mục và tên file\n",
    "date_dirs = [d.strftime(\"%Y%m%d\") for d in pd.date_range(START_DATE, END_DATE)]\n",
    "image_records_dict = {prefix: [] for prefix in ['b03_', 'b07_', 'b08_', 'b13_']}\n",
    "for date_dir in date_dirs:\n",
    "    date_path = os.path.join(PATH, date_dir)\n",
    "    if os.path.exists(date_path):\n",
    "        for time_dir in os.listdir(date_path):\n",
    "            time_path = os.path.join(date_path, time_dir)\n",
    "            if os.path.isdir(time_path):\n",
    "                try:\n",
    "                    dt = datetime.datetime.strptime(f\"{date_dir}T{time_dir}\", \"%Y%m%dT%H%M\")\n",
    "                    for file in os.listdir(time_path):\n",
    "                        for prefix in image_records_dict.keys():\n",
    "                            if file.lower().startswith(prefix) and file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                                img_path = os.path.join(time_path, file)\n",
    "                                image_records_dict[prefix].append((img_path, dt))\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi xử lý thư mục {time_path}: {e}\")\n",
    "                    continue\n",
    "for prefix in image_records_dict:\n",
    "    image_records_dict[prefix].sort(key=lambda x: x[1])\n",
    "    \n",
    "sequences_images_processed, sequences_times = preprocess_images(image_records_dict)\n",
    "\n",
    "def prepare_dataset_with_processed_images(sequences_images_processed, sequences_times):\n",
    "    \"\"\"Ghép dữ liệu ảnh với chuỗi GHI_CS đã chuẩn hóa và tạo tf.data.Dataset.\"\"\"\n",
    "    print(\"\\n🔄 Đang ghép dữ liệu ảnh với GHI_CS...\")\n",
    "    sequences_p_uoc = []\n",
    "    targets = []\n",
    "    valid_sequences_images = []\n",
    "    valid_sequences_times = []\n",
    "    for i, (img_seq, seq_time) in enumerate(zip(sequences_images_processed, sequences_times)):\n",
    "        start_idx = i\n",
    "        p_uoc_seq = [power_lookup.get(image_records_dict['b03_'][start_idx + j][1], 0.0) for j in range(SEQ_LENGTH)]\n",
    "        target_dts = [image_records_dict['b03_'][start_idx + SEQ_LENGTH + j][1] for j in range(PRED_LENGTH)]\n",
    "        target_powers = [power_lookup.get(dt, -1.0) for dt in target_dts]\n",
    "        if all(power != -1.0 for power in target_powers):\n",
    "            valid_sequences_images.append(img_seq)\n",
    "            sequences_p_uoc.append(p_uoc_seq)\n",
    "            targets.append(target_powers)\n",
    "            valid_sequences_times.append(seq_time)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        (np.array(valid_sequences_images), np.array(sequences_p_uoc)),\n",
    "        np.array(targets)\n",
    "    ))\n",
    "    # Có thể thêm shuffle nếu dataset lớn\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    print(f\"✅ Dataset đã sẵn sàng với {len(valid_sequences_images)} mẫu\")\n",
    "    return ds, valid_sequences_times\n",
    "\n",
    "dataset, sequences_times_train = prepare_dataset_with_processed_images(sequences_images_processed, sequences_times)\n",
    "\n",
    "# ---------- PHẦN 4: XÂY DỰNG MÔ HÌNH CẢI TIẾN ----------\n",
    "def build_model():\n",
    "    # Nhánh xử lý ảnh\n",
    "    input_images = layers.Input(shape=(SEQ_LENGTH, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS))\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu'))(input_images)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D(2, 2))(x)\n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu'))(x)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D(2, 2))(x)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    \n",
    "    # Nhánh dữ liệu GHI_CS (chuỗi đã chuẩn hóa)\n",
    "    input_p_uoc = layers.Input(shape=(SEQ_LENGTH,))\n",
    "    p_uoc_features = layers.Reshape((SEQ_LENGTH, 1))(input_p_uoc)\n",
    "    \n",
    "    # Ghép các đặc trưng\n",
    "    combined = layers.Concatenate(axis=-1)([x, p_uoc_features])\n",
    "    # Sử dụng LSTM cải tiến (có thể thử dùng Bidirectional)\n",
    "    lstm_out = layers.Bidirectional(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))(combined)\n",
    "    # Có thể thêm một vài lớp Dense để cải thiện khả năng học\n",
    "    dense_out = layers.Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = layers.Dropout(0.3)(dense_out)\n",
    "    output = layers.Dense(PRED_LENGTH)(dense_out)\n",
    "    \n",
    "    model = models.Model(inputs=[input_images, input_p_uoc], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# ---------- PHẦN 5: HUẤN LUYỆN VỚI CALLBACKS ----------\n",
    "def train_model(dataset):\n",
    "    model = build_model()\n",
    "    \n",
    "    # Định nghĩa các callbacks\n",
    "    early_stop = callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, verbose=1)\n",
    "    checkpoint = callbacks.ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "    \n",
    "    history = model.fit(dataset, epochs=EPOCHS, callbacks=[early_stop, reduce_lr, checkpoint], verbose=1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['mae'], label='MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Giá trị')\n",
    "    plt.title('Training Loss và MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "model, history = train_model(dataset)\n",
    "\n",
    "# ---------- PHẦN 6: KIỂM THỬ MÔ HÌNH ----------\n",
    "def test_model(model, scaler, test_start_date, test_end_date):\n",
    "    \"\"\"Test the model with the given date range.\"\"\"\n",
    "    print(f\"\\n🔄 Testing model for period: {test_start_date} to {test_end_date}\")\n",
    "    global START_DATE, END_DATE\n",
    "    START_DATE, END_DATE = test_start_date, test_end_date\n",
    "    \n",
    "    date_dirs = [d.strftime(\"%Y%m%d\") for d in pd.date_range(START_DATE, END_DATE)]\n",
    "    if not date_dirs:\n",
    "        print(\"⚠️ No dates in the specified range!\")\n",
    "        return None, None\n",
    "        \n",
    "    test_image_records_dict = {prefix: [] for prefix in ['b03_', 'b07_', 'b08_', 'b13_']}\n",
    "    for date_dir in date_dirs:\n",
    "        date_path = os.path.join(PATH, date_dir)\n",
    "        if os.path.exists(date_path):\n",
    "            for time_dir in os.listdir(date_path):\n",
    "                time_path = os.path.join(date_path, time_dir)\n",
    "                if os.path.isdir(time_path):\n",
    "                    try:\n",
    "                        dt = datetime.datetime.strptime(f\"{date_dir}T{time_dir}\", \"%Y%m%dT%H%M\")\n",
    "                        for file in os.listdir(time_path):\n",
    "                            for prefix in test_image_records_dict.keys():\n",
    "                                if file.lower().startswith(prefix) and file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                                    img_path = os.path.join(time_path, file)\n",
    "                                    test_image_records_dict[prefix].append((img_path, dt))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Lỗi xử lý {time_path}: {e}\")\n",
    "                        continue\n",
    "    for prefix in test_image_records_dict:\n",
    "        test_image_records_dict[prefix].sort(key=lambda x: x[1])\n",
    "    \n",
    "    sequences_images_test, sequences_times_test = preprocess_images(test_image_records_dict)\n",
    "    test_dataset, sequences_times = prepare_dataset_with_processed_images(sequences_images_test, sequences_times_test)\n",
    "    \n",
    "    # Lọc dữ liệu trong khoảng giờ 5h-19h\n",
    "    filtered_indices = [i for i, t in enumerate(sequences_times) if 5 <= t.hour <= 19]\n",
    "    if not filtered_indices:\n",
    "        print(\"⚠️ Không có dữ liệu trong khoảng 5h-19h!\")\n",
    "        return None, None\n",
    "    \n",
    "    test_loss, test_mae = model.evaluate(test_dataset, verbose=1)\n",
    "    print(f\"✅ Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    \n",
    "    predictions = model.predict(test_dataset)\n",
    "    true_values = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "    true_values = scaler.inverse_transform(true_values)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    filtered_true_values = true_values[filtered_indices]\n",
    "    filtered_predictions = predictions[filtered_indices]\n",
    "    filtered_times = [sequences_times[i] for i in filtered_indices]\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(filtered_times, filtered_true_values[:, 0], label='Thực tế bước 1', color='blue')\n",
    "    plt.plot(filtered_times, filtered_predictions[:, 0], label='Dự đoán bước 1', color='blue', linestyle='--')\n",
    "    plt.plot(filtered_times, filtered_true_values[:, 5], label='Thực tế bước 6', color='red')\n",
    "    plt.plot(filtered_times, filtered_predictions[:, 5], label='Dự đoán bước 6', color='red', linestyle='--')\n",
    "    plt.xlabel('Thời gian')\n",
    "    plt.ylabel('Giá trị GHI_CS')\n",
    "    plt.title('So sánh thực tế và dự đoán (Bước 1 & 6)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    def calculate_mape(true, pred):\n",
    "        mask = true != 0\n",
    "        return np.mean(np.abs((true[mask] - pred[mask]) / true[mask])) * 100 if mask.any() else float('nan')\n",
    "    \n",
    "    mape_step1 = calculate_mape(filtered_true_values[:, 0], filtered_predictions[:, 0])\n",
    "    mape_step6 = calculate_mape(filtered_true_values[:, 5], filtered_predictions[:, 5])\n",
    "test_start_date = datetime.datetime(2025, 2, 1)\n",
    "test_end_date = datetime.datetime(2025, 2, 1)\n",
    "true_values, predictions = test_model(model, scaler, test_start_date, test_end_date)\n",
    "\n",
    "if true_values is not None and predictions is not None:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(true_values[:, 5], label='Thực tế bước 6', color='red')\n",
    "    plt.plot(predictions[:, 5], label='Dự đoán bước 6', color='red', linestyle='--')\n",
    "    plt.xlabel('Thời gian')\n",
    "    plt.ylabel('Giá trị GHI_CS')\n",
    "    plt.title('So sánh thực tế và dự đoán (Bước 6)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ No valid data available for plotting\")\n",
    "plt.ylabel('Giá trị GHI_CS')\n",
    "plt.title('So sánh thực tế và dự đoán (Bước 6)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
