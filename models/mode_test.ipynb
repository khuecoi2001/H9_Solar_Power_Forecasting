{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ ƒêang x·ª≠ l√Ω ·∫£nh th√†nh chu·ªói d·ªØ li·ªáu multi-channel...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m image_records_dict:\n\u001b[0;32m    110\u001b[0m     image_records_dict[prefix]\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 112\u001b[0m sequences_images_processed, sequences_times \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_records_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_dataset_with_processed_images\u001b[39m(sequences_images_processed, sequences_times):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gh√©p d·ªØ li·ªáu ·∫£nh v·ªõi chu·ªói GHI_CS ƒë√£ chu·∫©n h√≥a v√† t·∫°o tf.data.Dataset.\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m, in \u001b[0;36mpreprocess_images\u001b[1;34m(image_records_dict)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m time_window:\n\u001b[0;32m     77\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((p \u001b[38;5;28;01mfor\u001b[39;00m p, dt \u001b[38;5;129;01min\u001b[39;00m image_records_dict[prefix] \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m==\u001b[39m t), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 78\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(IMG_SIZE \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     79\u001b[0m     channel_seq\u001b[38;5;241m.\u001b[39mappend(img\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     80\u001b[0m multi_channel_seq\u001b[38;5;241m.\u001b[39mappend(channel_seq)\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36mload_and_process_image\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load image from disk, resize v√† normalize v·ªÅ kho·∫£ng [-1,1].\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# S·ª≠ d·ª•ng tf.image.decode_image c√≥ th·ªÉ t·ª± ƒë·ªông x·ª≠ l√Ω ƒë·ªãnh d·∫°ng\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image(img, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, expand_animations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:133\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_file\u001b[39m(filename, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:611\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m    614\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:634\u001b[0m, in \u001b[0;36mread_file_eager_fallback\u001b[1;34m(filename, name, ctx)\u001b[0m\n\u001b[0;32m    632\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [filename]\n\u001b[0;32m    633\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m    637\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m    638\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Khue\\H9_Solar_Power_Forecasting\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pvlib\n",
    "from pvlib import location\n",
    "\n",
    "# ---------- PH·∫¶N 1: T√çNH TO√ÅN D·ªÆ LI·ªÜU CLEAR SKY ----------\n",
    "# Define date range for GMT+7 (Asia/Saigon)\n",
    "start_date = pd.Timestamp('2025-01-01 00:00:00', tz='Asia/Saigon')\n",
    "end_date = pd.Timestamp('2025-03-14 23:59:59', tz='Asia/Saigon')\n",
    "\n",
    "lat, lon = 10.76477848, 106.3148294\n",
    "site = location.Location(lat, lon, tz='Asia/Saigon')\n",
    "\n",
    "times = pd.date_range(start=start_date, end=end_date, freq='10min', tz='Asia/Saigon')\n",
    "clearsky_data = site.get_clearsky(times).reset_index().rename(columns={'index': 'Time'})\n",
    "clearsky_data.Time = pd.to_datetime(clearsky_data.Time).dt.tz_localize(None)\n",
    "clearsky_data.set_index('Time', inplace=True)\n",
    "clearsky_data = clearsky_data[['ghi']].rename(columns={'ghi': 'GHI_CS'})\n",
    "\n",
    "# ---------- PH·∫¶N 2: X·ª¨ L√ù D·ªÆ LI·ªÜU GHI_CS ----------\n",
    "power_df = clearsky_data.copy().reset_index()\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "scaler = MinMaxScaler()\n",
    "power_df['GHI_CS_normalized'] = scaler.fit_transform(power_df[['GHI_CS']])\n",
    "power_lookup = power_df.set_index('Time')['GHI_CS_normalized'].to_dict()\n",
    "\n",
    "# ---------- PH·∫¶N 3: X·ª¨ L√ù ·∫¢NH V√Ä T·∫†O PIPELINE ----------\n",
    "SEQ_LENGTH = 24\n",
    "PRED_LENGTH = 24\n",
    "IMG_SIZE = (32, 32)\n",
    "NUM_CHANNELS = 4\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "START_DATE = datetime.datetime(2025, 1, 1)\n",
    "END_DATE = datetime.datetime(2025, 1, 14)\n",
    "PATH = r\"Z:\\Sky-image\\namnvn\\Data_process\\MT Solarpark 1\"\n",
    "\n",
    "def load_and_process_image(path):\n",
    "    \"\"\"Load image from disk, resize v√† normalize v·ªÅ kho·∫£ng [-1,1].\"\"\"\n",
    "    try:\n",
    "        img = tf.io.read_file(path)\n",
    "        # S·ª≠ d·ª•ng tf.image.decode_image c√≥ th·ªÉ t·ª± ƒë·ªông x·ª≠ l√Ω ƒë·ªãnh d·∫°ng\n",
    "        img = tf.image.decode_image(img, channels=1, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = (img / 127.5) - 1.0\n",
    "        return img.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói load ·∫£nh {path}: {e}\")\n",
    "        return np.zeros(IMG_SIZE + (1,), dtype=np.float32)\n",
    "\n",
    "def preprocess_images(image_records_dict):\n",
    "    \"\"\"Gh√©p c√°c k√™nh ·∫£nh th√†nh m·ªôt chu·ªói d·ªØ li·ªáu multi-channel.\"\"\"\n",
    "    print(\"\\nüîÑ ƒêang x·ª≠ l√Ω ·∫£nh th√†nh chu·ªói d·ªØ li·ªáu multi-channel...\")\n",
    "    prefixes = ['b03_', 'b07_', 'b08_', 'b13_']\n",
    "    sequences_images = []\n",
    "    sequences_times = []\n",
    "    \n",
    "    # T√¨m th·ªùi gian chung cho t·∫•t c·∫£ c√°c k√™nh\n",
    "    times = set.intersection(*(set(dt for _, dt in image_records_dict[prefix]) for prefix in prefixes))\n",
    "    times = sorted(times)\n",
    "    min_length = len(times) - SEQ_LENGTH - PRED_LENGTH + 1\n",
    "    \n",
    "    for i in range(max(0, min_length)):\n",
    "        time_window = times[i:i+SEQ_LENGTH]\n",
    "        if len(time_window) != SEQ_LENGTH:\n",
    "            continue\n",
    "        multi_channel_seq = []\n",
    "        for prefix in prefixes:\n",
    "            channel_seq = []\n",
    "            for t in time_window:\n",
    "                path = next((p for p, dt in image_records_dict[prefix] if dt == t), None)\n",
    "                img = load_and_process_image(path) if path else np.zeros(IMG_SIZE + (1,), dtype=np.float32)\n",
    "                channel_seq.append(img.squeeze())\n",
    "            multi_channel_seq.append(channel_seq)\n",
    "        # Stack th√†nh (SEQ_LENGTH, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS)\n",
    "        stacked_seq = np.stack(multi_channel_seq, axis=-1)\n",
    "        sequences_images.append(stacked_seq)\n",
    "        sequences_times.append(time_window[-1])\n",
    "    \n",
    "    sequences_images = np.array(sequences_images)\n",
    "    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω {len(sequences_images)} chu·ªói ·∫£nh, shape: {sequences_images.shape}\")\n",
    "    return sequences_images, sequences_times\n",
    "\n",
    "# T·∫°o image_records_dict s·ª≠ d·ª•ng c·∫•u tr√∫c th∆∞ m·ª•c v√† t√™n file\n",
    "date_dirs = [d.strftime(\"%Y%m%d\") for d in pd.date_range(START_DATE, END_DATE)]\n",
    "image_records_dict = {prefix: [] for prefix in ['b03_', 'b07_', 'b08_', 'b13_']}\n",
    "for date_dir in date_dirs:\n",
    "    date_path = os.path.join(PATH, date_dir)\n",
    "    if os.path.exists(date_path):\n",
    "        for time_dir in os.listdir(date_path):\n",
    "            time_path = os.path.join(date_path, time_dir)\n",
    "            if os.path.isdir(time_path):\n",
    "                try:\n",
    "                    dt = datetime.datetime.strptime(f\"{date_dir}T{time_dir}\", \"%Y%m%dT%H%M\")\n",
    "                    for file in os.listdir(time_path):\n",
    "                        for prefix in image_records_dict.keys():\n",
    "                            if file.lower().startswith(prefix) and file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                                img_path = os.path.join(time_path, file)\n",
    "                                image_records_dict[prefix].append((img_path, dt))\n",
    "                except Exception as e:\n",
    "                    print(f\"L·ªói x·ª≠ l√Ω th∆∞ m·ª•c {time_path}: {e}\")\n",
    "                    continue\n",
    "for prefix in image_records_dict:\n",
    "    image_records_dict[prefix].sort(key=lambda x: x[1])\n",
    "    \n",
    "sequences_images_processed, sequences_times = preprocess_images(image_records_dict)\n",
    "\n",
    "def prepare_dataset_with_processed_images(sequences_images_processed, sequences_times):\n",
    "    \"\"\"Gh√©p d·ªØ li·ªáu ·∫£nh v·ªõi chu·ªói GHI_CS ƒë√£ chu·∫©n h√≥a v√† t·∫°o tf.data.Dataset.\"\"\"\n",
    "    print(\"\\nüîÑ ƒêang gh√©p d·ªØ li·ªáu ·∫£nh v·ªõi GHI_CS...\")\n",
    "    sequences_p_uoc = []\n",
    "    targets = []\n",
    "    valid_sequences_images = []\n",
    "    valid_sequences_times = []\n",
    "    for i, (img_seq, seq_time) in enumerate(zip(sequences_images_processed, sequences_times)):\n",
    "        start_idx = i\n",
    "        p_uoc_seq = [power_lookup.get(image_records_dict['b03_'][start_idx + j][1], 0.0) for j in range(SEQ_LENGTH)]\n",
    "        target_dts = [image_records_dict['b03_'][start_idx + SEQ_LENGTH + j][1] for j in range(PRED_LENGTH)]\n",
    "        target_powers = [power_lookup.get(dt, -1.0) for dt in target_dts]\n",
    "        if all(power != -1.0 for power in target_powers):\n",
    "            valid_sequences_images.append(img_seq)\n",
    "            sequences_p_uoc.append(p_uoc_seq)\n",
    "            targets.append(target_powers)\n",
    "            valid_sequences_times.append(seq_time)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        (np.array(valid_sequences_images), np.array(sequences_p_uoc)),\n",
    "        np.array(targets)\n",
    "    ))\n",
    "    # C√≥ th·ªÉ th√™m shuffle n·∫øu dataset l·ªõn\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    print(f\"‚úÖ Dataset ƒë√£ s·∫µn s√†ng v·ªõi {len(valid_sequences_images)} m·∫´u\")\n",
    "    return ds, valid_sequences_times\n",
    "\n",
    "dataset, sequences_times_train = prepare_dataset_with_processed_images(sequences_images_processed, sequences_times)\n",
    "\n",
    "# ---------- PH·∫¶N 4: X√ÇY D·ª∞NG M√î H√åNH C·∫¢I TI·∫æN ----------\n",
    "def build_model():\n",
    "    # Nh√°nh x·ª≠ l√Ω ·∫£nh\n",
    "    input_images = layers.Input(shape=(SEQ_LENGTH, IMG_SIZE[0], IMG_SIZE[1], NUM_CHANNELS))\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu'))(input_images)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D(2, 2))(x)\n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu'))(x)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D(2, 2))(x)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    \n",
    "    # Nh√°nh d·ªØ li·ªáu GHI_CS (chu·ªói ƒë√£ chu·∫©n h√≥a)\n",
    "    input_p_uoc = layers.Input(shape=(SEQ_LENGTH,))\n",
    "    p_uoc_features = layers.Reshape((SEQ_LENGTH, 1))(input_p_uoc)\n",
    "    \n",
    "    # Gh√©p c√°c ƒë·∫∑c tr∆∞ng\n",
    "    combined = layers.Concatenate(axis=-1)([x, p_uoc_features])\n",
    "    # S·ª≠ d·ª•ng LSTM c·∫£i ti·∫øn (c√≥ th·ªÉ th·ª≠ d√πng Bidirectional)\n",
    "    lstm_out = layers.Bidirectional(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))(combined)\n",
    "    # C√≥ th·ªÉ th√™m m·ªôt v√†i l·ªõp Dense ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng h·ªçc\n",
    "    dense_out = layers.Dense(64, activation='relu')(lstm_out)\n",
    "    dense_out = layers.Dropout(0.3)(dense_out)\n",
    "    output = layers.Dense(PRED_LENGTH)(dense_out)\n",
    "    \n",
    "    model = models.Model(inputs=[input_images, input_p_uoc], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# ---------- PH·∫¶N 5: HU·∫§N LUY·ªÜN V·ªöI CALLBACKS ----------\n",
    "def train_model(dataset):\n",
    "    model = build_model()\n",
    "    \n",
    "    # ƒê·ªãnh nghƒ©a c√°c callbacks\n",
    "    early_stop = callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, verbose=1)\n",
    "    checkpoint = callbacks.ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "    \n",
    "    history = model.fit(dataset, epochs=EPOCHS, callbacks=[early_stop, reduce_lr, checkpoint], verbose=1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['mae'], label='MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Gi√° tr·ªã')\n",
    "    plt.title('Training Loss v√† MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "model, history = train_model(dataset)\n",
    "\n",
    "# ---------- PH·∫¶N 6: KI·ªÇM TH·ª¨ M√î H√åNH ----------\n",
    "def test_model(model, scaler, test_start_date, test_end_date):\n",
    "    \"\"\"Test the model with the given date range.\"\"\"\n",
    "    print(f\"\\nüîÑ Testing model for period: {test_start_date} to {test_end_date}\")\n",
    "    global START_DATE, END_DATE\n",
    "    START_DATE, END_DATE = test_start_date, test_end_date\n",
    "    \n",
    "    date_dirs = [d.strftime(\"%Y%m%d\") for d in pd.date_range(START_DATE, END_DATE)]\n",
    "    if not date_dirs:\n",
    "        print(\"‚ö†Ô∏è No dates in the specified range!\")\n",
    "        return None, None\n",
    "        \n",
    "    test_image_records_dict = {prefix: [] for prefix in ['b03_', 'b07_', 'b08_', 'b13_']}\n",
    "    for date_dir in date_dirs:\n",
    "        date_path = os.path.join(PATH, date_dir)\n",
    "        if os.path.exists(date_path):\n",
    "            for time_dir in os.listdir(date_path):\n",
    "                time_path = os.path.join(date_path, time_dir)\n",
    "                if os.path.isdir(time_path):\n",
    "                    try:\n",
    "                        dt = datetime.datetime.strptime(f\"{date_dir}T{time_dir}\", \"%Y%m%dT%H%M\")\n",
    "                        for file in os.listdir(time_path):\n",
    "                            for prefix in test_image_records_dict.keys():\n",
    "                                if file.lower().startswith(prefix) and file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                                    img_path = os.path.join(time_path, file)\n",
    "                                    test_image_records_dict[prefix].append((img_path, dt))\n",
    "                    except Exception as e:\n",
    "                        print(f\"L·ªói x·ª≠ l√Ω {time_path}: {e}\")\n",
    "                        continue\n",
    "    for prefix in test_image_records_dict:\n",
    "        test_image_records_dict[prefix].sort(key=lambda x: x[1])\n",
    "    \n",
    "    sequences_images_test, sequences_times_test = preprocess_images(test_image_records_dict)\n",
    "    test_dataset, sequences_times = prepare_dataset_with_processed_images(sequences_images_test, sequences_times_test)\n",
    "    \n",
    "    # L·ªçc d·ªØ li·ªáu trong kho·∫£ng gi·ªù 5h-19h\n",
    "    filtered_indices = [i for i, t in enumerate(sequences_times) if 5 <= t.hour <= 19]\n",
    "    if not filtered_indices:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu trong kho·∫£ng 5h-19h!\")\n",
    "        return None, None\n",
    "    \n",
    "    test_loss, test_mae = model.evaluate(test_dataset, verbose=1)\n",
    "    print(f\"‚úÖ Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    \n",
    "    predictions = model.predict(test_dataset)\n",
    "    true_values = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "    true_values = scaler.inverse_transform(true_values)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    filtered_true_values = true_values[filtered_indices]\n",
    "    filtered_predictions = predictions[filtered_indices]\n",
    "    filtered_times = [sequences_times[i] for i in filtered_indices]\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(filtered_times, filtered_true_values[:, 0], label='Th·ª±c t·∫ø b∆∞·ªõc 1', color='blue')\n",
    "    plt.plot(filtered_times, filtered_predictions[:, 0], label='D·ª± ƒëo√°n b∆∞·ªõc 1', color='blue', linestyle='--')\n",
    "    plt.plot(filtered_times, filtered_true_values[:, 5], label='Th·ª±c t·∫ø b∆∞·ªõc 6', color='red')\n",
    "    plt.plot(filtered_times, filtered_predictions[:, 5], label='D·ª± ƒëo√°n b∆∞·ªõc 6', color='red', linestyle='--')\n",
    "    plt.xlabel('Th·ªùi gian')\n",
    "    plt.ylabel('Gi√° tr·ªã GHI_CS')\n",
    "    plt.title('So s√°nh th·ª±c t·∫ø v√† d·ª± ƒëo√°n (B∆∞·ªõc 1 & 6)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    def calculate_mape(true, pred):\n",
    "        mask = true != 0\n",
    "        return np.mean(np.abs((true[mask] - pred[mask]) / true[mask])) * 100 if mask.any() else float('nan')\n",
    "    \n",
    "    mape_step1 = calculate_mape(filtered_true_values[:, 0], filtered_predictions[:, 0])\n",
    "    mape_step6 = calculate_mape(filtered_true_values[:, 5], filtered_predictions[:, 5])\n",
    "test_start_date = datetime.datetime(2025, 2, 1)\n",
    "test_end_date = datetime.datetime(2025, 2, 1)\n",
    "true_values, predictions = test_model(model, scaler, test_start_date, test_end_date)\n",
    "\n",
    "if true_values is not None and predictions is not None:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(true_values[:, 5], label='Th·ª±c t·∫ø b∆∞·ªõc 6', color='red')\n",
    "    plt.plot(predictions[:, 5], label='D·ª± ƒëo√°n b∆∞·ªõc 6', color='red', linestyle='--')\n",
    "    plt.xlabel('Th·ªùi gian')\n",
    "    plt.ylabel('Gi√° tr·ªã GHI_CS')\n",
    "    plt.title('So s√°nh th·ª±c t·∫ø v√† d·ª± ƒëo√°n (B∆∞·ªõc 6)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid data available for plotting\")\n",
    "plt.ylabel('Gi√° tr·ªã GHI_CS')\n",
    "plt.title('So s√°nh th·ª±c t·∫ø v√† d·ª± ƒëo√°n (B∆∞·ªõc 6)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
